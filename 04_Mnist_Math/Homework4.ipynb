{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow"
      ],
      "metadata": {
        "id": "dAK1ZcQm_BRY"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorboard"
      ],
      "metadata": {
        "id": "zI8LJbOiFxfT"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import datetime\n",
        "\n",
        "import tensorboard\n",
        "\n",
        "import tqdm\n"
      ],
      "metadata": {
        "id": "trXCpr1N8e9L"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. get mnist from tensorflow_datasets\n",
        "mnist = tfds.load(\"mnist\", split =[\"train\",\"test\"], as_supervised=True)\n",
        "train_ds = mnist[0]\n",
        "val_ds = mnist[1]"
      ],
      "metadata": {
        "id": "pEkyQgPI8hS8"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. write function to create the dataset that we want\n",
        "def preprocess_task1(data, batch_size):\n",
        "    # image should be float\n",
        "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
        "    # image should be flattened\n",
        "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
        "    # image vector will here have values between -1 and 1\n",
        "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
        "    # we want to have two mnist images in each example\n",
        "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
        "    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), \n",
        "                                     data.shuffle(2000)))\n",
        "    # map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *boolean\n",
        "    zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] + x2[1] >= 5))\n",
        "    # transform boolean target to int\n",
        "    zipped_ds = zipped_ds.map(lambda x1, x2, t: (x1,x2, tf.cast(t, tf.int32)))\n",
        "    # batch the dataset\n",
        "    zipped_ds = zipped_ds.batch(batch_size)\n",
        "    # prefetch\n",
        "    zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return zipped_ds\n"
      ],
      "metadata": {
        "id": "J5Wxhn3Fx79l"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. write function to create the dataset that we want\n",
        "def preprocess_task2(data, batch_size):\n",
        "    # image should be float\n",
        "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
        "    # image should be flattened\n",
        "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
        "    # image vector will here have values between -1 and 1\n",
        "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
        "    # we want to have two mnist images in each example\n",
        "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
        "    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), \n",
        "                                     data.shuffle(2000)))\n",
        "    # map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *boolean\n",
        "    zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] - x2[1]))\n",
        "   \n",
        "    zipped_ds = zipped_ds.map(lambda img1, img2, target: (img1, img2, tf.one_hot(target, depth=38)))\n",
        "    # batch the dataset\n",
        "    zipped_ds = zipped_ds.batch(batch_size)\n",
        "    # prefetch\n",
        "    zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return zipped_ds"
      ],
      "metadata": {
        "id": "SRpYuv1nx_J7"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_ds = preprocess_task1(train_ds, batch_size=32) #train_ds.apply(preprocess)\n",
        "#val_ds = preprocess_task1(val_ds, batch_size=32) #val_ds.apply(preprocess)"
      ],
      "metadata": {
        "id": "DmChdEtPx-hv"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''# check the contents of the dataset\n",
        "for img1, img2, label in train_ds.take(1):\n",
        "    print(img1.shape, img2.shape, label.shape)\n",
        "\n",
        "train_ds.map(lambda x1, x2, t: (x1, x2, tf.cast(t, tf.int32)))'''"
      ],
      "metadata": {
        "id": "wCoMwLr78lYs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8701fd63-750d-4a36-cdf2-eb3db24bec52"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# check the contents of the dataset\\nfor img1, img2, label in train_ds.take(1):\\n    print(img1.shape, img2.shape, label.shape)\\n\\ntrain_ds.map(lambda x1, x2, t: (x1, x2, tf.cast(t, tf.int32)))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_summary_writers(config_name):\n",
        "    \n",
        "    # Define where to save the logs\n",
        "    # along with this, you may want to save a config file with the same name so you know what the hyperparameters were used\n",
        "    # alternatively make a copy of the code that is used for later reference\n",
        "    \n",
        "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
        "    val_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
        "\n",
        "    # log writer for training metrics\n",
        "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
        "\n",
        "    # log writer for validation metrics\n",
        "    val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
        "    \n",
        "    return train_summary_writer, val_summary_writer\n",
        "\n",
        "train_summary_writer, val_summary_writer = create_summary_writers(config_name=\"RUN1\")"
      ],
      "metadata": {
        "id": "sYVSa0Bi4DQu"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwinMNISTModel(tf.keras.Model):\n",
        "\n",
        "    # 1. constructor\n",
        "    def __init__(self, optimizer = \"Adam\", n_of_task = 1 ):\n",
        "        super().__init__()\n",
        "        # inherit functionality from parent class\n",
        "\n",
        "        # optimizer, loss function and metrics\n",
        "        self.metrics_list = [tf.keras.metrics.BinaryAccuracy(),\n",
        "                             tf.keras.metrics.Mean(name=\"loss\")] \n",
        "        \n",
        "        if(optimizer == \"Adam\"):\n",
        "          self.optimizer = tf.keras.optimizers.Adam()\n",
        "        elif(optimizer == \"SGD\"):\n",
        "          self.optimizer = tf.keras.optimizers.SGD()\n",
        "\n",
        "        if n_of_task == 1:\n",
        "            self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
        "        if n_of_task == 2:\n",
        "            self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "        # layers to encode the images (both layers used for both images)\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
        "        \n",
        "        self.dense3 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
        "        \n",
        "        self.out_layer = tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)\n",
        "        \n",
        "    # 2. call method (forward computation)\n",
        "    def call(self, images, training=False):\n",
        "        img1, img2 = images\n",
        "        \n",
        "        img1_x = self.dense1(img1)\n",
        "        img1_x = self.dense2(img1_x)\n",
        "        \n",
        "        img2_x = self.dense1(img2)\n",
        "        img2_x = self.dense2(img2_x)\n",
        "        \n",
        "        combined_x = tf.concat([img1_x, img2_x ], axis=1)\n",
        "        combined_x = self.dense3(combined_x)\n",
        "        return self.out_layer(combined_x)\n",
        "\n",
        "    # 3. metrics property\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return self.metrics_list\n",
        "        # return a list with all metrics in the model\n",
        "\n",
        "    # 4. reset all metrics objects\n",
        "    def reset_metrics(self):\n",
        "        for metric in self.metrics:\n",
        "            metric.reset_states()\n",
        "\n",
        "    # 5. train step method\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        img1, img2, label = data\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self((img1, img2), training=True)\n",
        "            loss = self.loss_function(label, output)\n",
        "            \n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        \n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        \n",
        "        # update the state of the metrics according to loss\n",
        "        self.metrics[0].update_state(label, output)\n",
        "        self.metrics[1].update_state(loss)\n",
        "        \n",
        "        # return a dictionary with metric names as keys and metric results as values\n",
        "        return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "    # 6. test_step method\n",
        "    @tf.function\n",
        "    def test_step(self, data):\n",
        "        img1, img2, label = data\n",
        "        # same as train step (without parameter updates)\n",
        "        output = self((img1, img2), training=False)\n",
        "        loss = self.loss_function(label, output)\n",
        "        self.metrics[0].update_state(label, output)\n",
        "        self.metrics[1].update_state(loss)\n",
        "        \n",
        "        return {m.name : m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "9R3tfNkf-_JJ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, train_ds, val_ds, start_epoch, epochs, train_summary_writer, val_summary_writer, save_path):\n",
        "    for e in range(start_epoch, epochs):\n",
        "        for data in tqdm.tqdm(train_ds, position=0, leave=True):\n",
        "            metrics = model.train_step(data)\n",
        "\n",
        "        # 3. log and print training metrics\n",
        "\n",
        "        with train_summary_writer.as_default():\n",
        "            # for scalar metrics:\n",
        "            for metric in model.metrics:\n",
        "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
        "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
        "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
        "        \n",
        "        #print the metrics\n",
        "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()]) \n",
        "\n",
        "        # 4. reset metric objects\n",
        "        model.reset_metrics()\n",
        "\n",
        "\n",
        "        # 5. evaluate on validation data\n",
        "        for data in val_ds:\n",
        "            metrics = model.test_step(data)\n",
        "\n",
        "\n",
        "        # 6. log validation metrics\n",
        "\n",
        "        with val_summary_writer.as_default():\n",
        "            # for scalar metrics:\n",
        "            for metric in model.metrics:\n",
        "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
        "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
        "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
        "            \n",
        "        print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
        "\n",
        "        # 7. reset metric objects\n",
        "        model.reset_metrics()\n",
        "\n",
        "    # 8. save model weights if save_path is given\n",
        "    if save_path:\n",
        "        model.save_weights(save_path) "
      ],
      "metadata": {
        "id": "GQKGJBpEGtJi"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training and test data\n",
        "#Subtask1\n",
        "train_ds_task1 = preprocess_task1(train_ds, batch_size=32)\n",
        "val_ds_task1 = preprocess_task1(val_ds, batch_size=32) \n",
        "\n",
        "#training and test data\n",
        "#Subtask2\n",
        "train_ds_task2 = preprocess_task2(train_ds, batch_size=32)\n",
        "val_ds_task2 = preprocess_task2(val_ds, batch_size=32) \n",
        "\n",
        "\n",
        "# 1. instantiate model\n",
        "#Adam Optimizer\n",
        "model1 = TwinMNISTModel(\"Adam\", 1)\n",
        "model2 = TwinMNISTModel(\"Adam\", 2)\n",
        "\n",
        "# 2. choose a path to save the weights\n",
        "save_path = \"trained_model_RUN1\"\n",
        "\n",
        "print(\"Adam optimizer\")\n",
        "print(\"Subtask1\")\n",
        "training_loop(model=model1,\n",
        "    train_ds=train_ds_task1,\n",
        "    val_ds=val_ds_task1,\n",
        "    start_epoch=0,\n",
        "    epochs=10,\n",
        "    train_summary_writer=train_summary_writer,\n",
        "    val_summary_writer=val_summary_writer,\n",
        "    save_path=save_path)\n",
        "\n",
        "print(\"Subtask2\")\n",
        "training_loop(model=model2,\n",
        "    train_ds=train_ds_task2,\n",
        "    val_ds=val_ds_task2,\n",
        "    start_epoch=0,\n",
        "    epochs=10,\n",
        "    train_summary_writer=train_summary_writer,\n",
        "    val_summary_writer=val_summary_writer,\n",
        "    save_path=save_path)\n",
        "\n",
        "print(\"SGD optimizer\")\n",
        "#SGD Optimizer\n",
        "model1 = TwinMNISTModel(\"SGD\", 1)\n",
        "model2 = TwinMNISTModel(\"SGD\", 2)\n",
        "\n",
        "#Subtask1\n",
        "training_loop(model=model1,\n",
        "    train_ds=train_ds_task1,\n",
        "    val_ds=val_ds_task1,\n",
        "    start_epoch=0,\n",
        "    epochs=10,\n",
        "    train_summary_writer=train_summary_writer,\n",
        "    val_summary_writer=val_summary_writer,\n",
        "    save_path=save_path)\n",
        "\n",
        "print(\"Subtask2\")\n",
        "#Subtask2\n",
        "training_loop(model=model2,\n",
        "    train_ds=train_ds_task2,\n",
        "    val_ds=val_ds_task2,\n",
        "    start_epoch=0,\n",
        "    epochs=10,\n",
        "    train_summary_writer=train_summary_writer,\n",
        "    val_summary_writer=val_summary_writer,\n",
        "    save_path=save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoAelTWDG5vj",
        "outputId": "c89bf552-2f72-4d2e-a0ee-ec2c7360cf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam optimizer\n",
            "Subtask1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:25<00:00, 73.92it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['binary_accuracy: 0.9424833059310913', 'loss: 0.15026351809501648']\n",
            "['val_binary_accuracy: 0.9733999967575073', 'val_loss: 0.07786554098129272']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:17<00:00, 104.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['binary_accuracy: 0.9718833565711975', 'loss: 0.07965642213821411']\n",
            "['val_binary_accuracy: 0.9757000207901001', 'val_loss: 0.07104188948869705']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:20<00:00, 91.50it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['binary_accuracy: 0.9771833419799805', 'loss: 0.06503148376941681']\n",
            "['val_binary_accuracy: 0.9797999858856201', 'val_loss: 0.058088380843400955']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:18<00:00, 101.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['binary_accuracy: 0.979366660118103', 'loss: 0.059940315783023834']\n",
            "['val_binary_accuracy: 0.9818000197410583', 'val_loss: 0.05572908744215965']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 112.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['binary_accuracy: 0.9824000000953674', 'loss: 0.051684293895959854']\n",
            "['val_binary_accuracy: 0.9815999865531921', 'val_loss: 0.05700656771659851']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:20<00:00, 91.52it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['binary_accuracy: 0.9830166697502136', 'loss: 0.04811704158782959']\n",
            "['val_binary_accuracy: 0.9818999767303467', 'val_loss: 0.05286778509616852']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 788/1875 [00:07<00:09, 112.02it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dH2T7mjHG6Mr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}