{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import datetime\n",
    "\n",
    "# magic line only needed in jupyter notebooks!\n",
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with as_supervised=True to import labels\n",
    "mnist = tfds.load(\"mnist\", split =[\"train\",\"test\"], as_supervised=True)\n",
    "train_ds = mnist[0]\n",
    "val_ds = mnist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 19), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# 2. write function to create the dataset that we want\n",
    "def preprocess(data, batch_size, task):\n",
    "    # image should be float\n",
    "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
    "    # image should be flattened\n",
    "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
    "    # image vector will here have values between -1 and 1\n",
    "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
    "    # we want to have two mnist images in each example\n",
    "    \n",
    "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
    "    data = tf.data.Dataset.zip((data.shuffle(2000), data.shuffle(2000)))\n",
    "    \n",
    "    # map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *boolean\n",
    "    if(task==1):\n",
    "        data = data.map(lambda x1, x2: (x1[0], x2[0], x1[1]+x2[1]>=5))\n",
    "        # transform boolean target to int\n",
    "        data = data.map(lambda x1, x2, t: (x1,x2, tf.cast(t, tf.int32)))\n",
    "    else:\n",
    "        # possible 19 results for a-b [-9, 9], encode as one hot vector for classification\n",
    "        data = data.map(lambda x1, x2: (x1[0], x2[0], tf.one_hot((x1[1]-x2[1]), 19, dtype=tf.float32)))\n",
    "    \n",
    "    # batch the dataset\n",
    "    data = data.batch(batch_size)\n",
    "    # prefetch\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data\n",
    "\n",
    "train_ds1 = preprocess(train_ds, batch_size=32, task=1) #train_ds.apply(preprocess)\n",
    "val_ds1 = preprocess(val_ds, batch_size=32, task=1) #val_ds.apply(preprocess)\n",
    "\n",
    "train_ds2 = preprocess(train_ds, batch_size=32, task=2) #train_ds.apply(preprocess)+\n",
    "val_ds2 = preprocess(val_ds, batch_size=32, task=2) #val_ds.apply(preprocess)\n",
    "print(train_ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryModel(tf.keras.Model):\n",
    "\n",
    "    # 1. constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inherit functionality from parent class\n",
    "\n",
    "        # optimizer, loss function and metrics\n",
    "        self.metrics_list = [tf.keras.metrics.BinaryAccuracy(name=\"subtask1_accuracy\"), tf.keras.metrics.Mean(name=\"subtask1_loss\")]\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "        # layers to encode the images (both layers used for both images)\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        \n",
    "        self.dense3 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        \n",
    "        self.out_layer = tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)\n",
    "        \n",
    "    # 2. call method (forward computation)\n",
    "    def call(self, images, training=False):\n",
    "        img1, img2 = images\n",
    "        \n",
    "        img1_x = self.dense1(img1)\n",
    "        img1_x = self.dense2(img1_x)\n",
    "        \n",
    "        img2_x = self.dense1(img2)\n",
    "        img2_x = self.dense2(img2_x)\n",
    "        \n",
    "        combined_x = tf.concat([img1_x, img2_x ], axis=1)\n",
    "        combined_x = self.dense3(combined_x)\n",
    "        return self.out_layer(combined_x)\n",
    "\n",
    "    # 3. metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    # 5. train step method\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update the state of the metrics according to loss\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        # return a dictionary with metric names as keys and metric results as values\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "    # 6. test_step method\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        # same as train step (without parameter updates)\n",
    "        output = self((img1, img2), training=False)\n",
    "        loss = self.loss_function(label, output)\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalModel(tf.keras.Model):\n",
    "\n",
    "    # 1. constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inherit functionality from parent class\n",
    "\n",
    "        # optimizer, loss function and metrics\n",
    "        self.metrics_list = [tf.keras.metrics.CategoricalAccuracy(name=\"subtask2_accuracy\"), tf.keras.metrics.Mean(name=\"subtask2_loss\")]\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "        # layers to encode the images (both layers used for both images)\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        \n",
    "        self.dense3 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
    "        \n",
    "        self.out_layer = tf.keras.layers.Dense(19,activation=tf.nn.softmax)\n",
    "        \n",
    "    # 2. call method (forward computation)\n",
    "    def call(self, images, training=False):\n",
    "        img1, img2 = images\n",
    "        \n",
    "        img1_x = self.dense1(img1)\n",
    "        img1_x = self.dense2(img1_x)\n",
    "        \n",
    "        img2_x = self.dense1(img2)\n",
    "        img2_x = self.dense2(img2_x)\n",
    "        \n",
    "        combined_x = tf.concat([img1_x, img2_x ], axis=1)\n",
    "        combined_x = self.dense3(combined_x)\n",
    "        return self.out_layer(combined_x)\n",
    "\n",
    "    # 3. metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    # 5. train step method\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update the state of the metrics according to loss\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        # return a dictionary with metric names as keys and metric results as values\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "    # 6. test_step method\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        # same as train step (without parameter updates)\n",
    "        output = self((img1, img2), training=False)\n",
    "        loss = self.loss_function(label, output)\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_writers(config_name):\n",
    "    \n",
    "    # Define where to save the logs\n",
    "    # along with this, you may want to save a config file with the same name so you know what the hyperparameters were used\n",
    "    # alternatively make a copy of the code that is used for later reference\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "    val_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
    "\n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "    # log writer for validation metrics\n",
    "    val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
    "    \n",
    "    return train_summary_writer, val_summary_writer\n",
    "\n",
    "train_summary_writer_subtask1, val_summary_writer_subtask1 = create_summary_writers(config_name=\"subtask_1_RUN1\")\n",
    "train_summary_writer_subtask2, val_summary_writer_subtask2 = create_summary_writers(config_name=\"subtask_2_RUN3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def training_loop(model, train_ds, val_ds, start_epoch,\n",
    "                  epochs, train_summary_writer, \n",
    "                  val_summary_writer, save_path):\n",
    "\n",
    "    # 1. iterate over epochs\n",
    "    for e in range(start_epoch, epochs):\n",
    "\n",
    "        # 2. train steps on all batches in the training data\n",
    "        for data in tqdm.tqdm(train_ds, position=0, leave=True):\n",
    "            metrics = model.train_step(data) # we save to metrics because we want to print it and tensorboard\n",
    "\n",
    "        ## Training data\n",
    "        # 3. log and print training metrics\n",
    "        with train_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "        \n",
    "        #print the metrics\n",
    "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        \n",
    "        # 4. reset metric objects for next epch\n",
    "        model.reset_metrics()\n",
    "\n",
    "        #####################################################\n",
    "\n",
    "        ## Validation data\n",
    "        # 5. evaluate on validation data\n",
    "        for data in val_ds:\n",
    "            metrics = model.test_step(data)\n",
    "        \n",
    "        # 6. log validation metrics\n",
    "        with val_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "            \n",
    "        print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        # 7. reset metric objects\n",
    "        model.reset_metrics()\n",
    "        \n",
    "    # 8. save model weights if save_path is given\n",
    "    if save_path:\n",
    "        model.save_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-28c7459617f7338e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-28c7459617f7338e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open the tensorboard logs\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]2022-11-26 17:09:41.251733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 1875/1875 [00:20<00:00, 93.07it/s] \n",
      "2022-11-26 17:10:01.221584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12155000120401382', 'loss: 4325623.5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 17:10:03.827548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val_accuracy: 0.021400000900030136', 'val_loss: 17348446.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.1200999990105629', 'loss: 49680700.0']\n",
      "['val_accuracy: 0.08980000764131546', 'val_loss: 74761424.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 99.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12183333188295364', 'loss: 152950960.0']\n",
      "['val_accuracy: 0.5485000014305115', 'val_loss: 270329760.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.11883333325386047', 'loss: 319726496.0']\n",
      "['val_accuracy: 0.050700001418590546', 'val_loss: 271315840.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 98.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12071666866540909', 'loss: 551154944.0']\n",
      "['val_accuracy: 0.07810000330209732', 'val_loss: 830948672.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 97.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12076666951179504', 'loss: 888380032.0']\n",
      "['val_accuracy: 0.03350000083446503', 'val_loss: 603351616.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 99.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12248333543539047', 'loss: 1281678336.0']\n",
      "['val_accuracy: 0.08050000667572021', 'val_loss: 1202204672.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 99.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12323333323001862', 'loss: 1773709440.0']\n",
      "['val_accuracy: 0.04780000075697899', 'val_loss: 2012207616.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 99.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12098333239555359', 'loss: 2377750528.0']\n",
      "['val_accuracy: 0.07930000126361847', 'val_loss: 3078215936.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 98.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12301667034626007', 'loss: 3115229952.0']\n",
      "['val_accuracy: 0.08670000731945038', 'val_loss: 4714269696.0']\n"
     ]
    }
   ],
   "source": [
    "# 1. instantiate model\n",
    "model_subtask1 = BinaryModel()\n",
    "model_subtask2 = CategoricalModel()\n",
    "\n",
    "# 2. choose a path to save the weights\n",
    "save_path_subtask1 = \"subtask1_trained_model_RUN1\"\n",
    "save_path_subtask2 = \"subtask2_trained_model_RUN3\"\n",
    "\n",
    "# 3. pass arguments to training loop function\n",
    "training_loop(model=model_subtask2,\n",
    "    train_ds=train_ds2,\n",
    "    val_ds=val_ds2,\n",
    "    start_epoch=0,\n",
    "    epochs=10,\n",
    "    train_summary_writer=train_summary_writer_subtask2,\n",
    "    val_summary_writer=val_summary_writer_subtask2,\n",
    "    save_path=save_path_subtask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model:\n",
    "fresh_model = TwinMNISTModel()\n",
    "\n",
    "# build the model's parameters by calling it on input\n",
    "for img1,img2,label in train_ds:\n",
    "    fresh_model((img1,img2));\n",
    "    break\n",
    "\n",
    "# load the saved weights\n",
    "model = fresh_model.load_weights(save_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
